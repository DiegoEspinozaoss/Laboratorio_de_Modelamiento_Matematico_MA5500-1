#%%
import os, glob
import numpy as np
import matplotlib.pyplot as plt
from scipy.sparse import csr_matrix
from scipy.sparse.linalg import eigs
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import random
 
SEED = 42 

os.environ["PYTHONHASHSEED"] = str(SEED)
os.environ["OMP_NUM_THREADS"] = "1"

random.seed(SEED)
np.random.seed(SEED)



def load_transport_matrix(edge_path, N=None, one_indexed=True):
    """
    Lee una matriz de transporte desde archivo con lÃ­neas: 'i j count'
    Devuelve P (CSR) estocÃ¡stica por filas: P = D^{-1} A
    """
    data = np.loadtxt(edge_path, dtype=float)
    if data.ndim == 1:  
        data = data.reshape(1, -1)
    i, j, w = data[:,0].astype(int), data[:,1].astype(int), data[:,2]
    if one_indexed:
        i -= 1; j -= 1
    N = int(N or max(i.max(), j.max()) + 1)
    A = csr_matrix((w, (i, j)), shape=(N, N))
    rowsum = np.asarray(A.sum(axis=1)).ravel()
    rowsum[rowsum == 0] = 1.0  
    P = A.multiply((1.0 / rowsum)[:, None]).tocsr()
    return P


def plot_eigs_complex(P, k=200, title="Espectro de autovalores en el plano complejo"):
    """
    Calcula y grafica los k autovalores dominantes (de mayor magnitud) de la matriz de transporte P.
    Importante: no se calculan los N autovalores (N puede ser miles),
    solo los mÃ¡s dominantes, ya que calcular todos consumirÃ­a mucha memoria y tiempo.
    
    InterpretaciÃ³n:
    - El autovalor Î»=1 representa la componente estacionaria (estado de equilibrio).
    - Los autovalores con |Î»| < 1 representan modos de relajaciÃ³n:
      indican la velocidad con la que el sistema converge al equilibrio.
      Cuanto mÃ¡s cercano a 1 estÃ© |Î»|, mÃ¡s lento es ese modo.
    """
    N = P.shape[0]
    k = min(k, max(1, N-2))
    print(f"\nCalculando los {k} autovalores dominantes de un total de {N} posibles...")
    print("  (Los autovalores dominantes capturan la dinÃ¡mica global; calcular todos serÃ­a costoso en tiempo y memoria.)\n")

    vals = eigs(P, k=k, which='LM', return_eigenvectors=False)

    plt.figure(figsize=(6,6))
    plt.scatter(vals.real, vals.imag, s=16)

    t = np.linspace(0, 2*np.pi, 400)
    plt.plot(np.cos(t), np.sin(t), linewidth=1)
    plt.axhline(0, linewidth=0.5)
    plt.axvline(0, linewidth=0.5)
    plt.gca().set_aspect('equal', 'box')
    plt.title(f"{title}\n({k} autovalores dominantes de {N} posibles)")
    plt.xlabel('Re(Î»)')
    plt.ylabel('Im(Î»)')
    plt.grid(True, alpha=0.3)
    plt.show()

    print("""
    InterpretaciÃ³n espectral:
    - Î» = 1  â†’ componente estacionaria: el sistema estÃ¡ en equilibrio (flujo neto cero).
    - 0 < |Î»| < 1 â†’ modos de relajaciÃ³n: describen cÃ³mo se disipan o mezclan las trayectorias.
    - |Î»| cercano a 1 â†’ relajaciÃ³n lenta (estructuras persistentes).
    - |Î»| pequeÃ±o â†’ relajaciÃ³n rÃ¡pida (zonas bien mezcladas).
    """)

    return vals



def spectral_clustering_from_P(P, n_vecs=6, n_clusters=6, random_state=SEED):
    """
    Usa los n_vecs autovectores dominantes (excluyendo el trivial) para embebido espectral y KMeans.
    Devuelve labels (nodos -> cluster), emb (matriz de features para cada nodo).
    """
    N = P.shape[0]
    n_vecs = max(2, n_vecs)
    
    k = min(n_vecs + 1, N-2)
    vals, vecs = eigs(P, k=k, which='LM')
    
    idx = np.argsort(np.abs(vals))[::-1]
    vals, vecs = vals[idx], vecs[:, idx]
    
    trivial_idx = np.argmin(np.abs(vals - 1))
    mask = np.ones(len(vals), dtype=bool)
    mask[trivial_idx] = False
    vals_nt = vals[mask][:n_vecs]
    vecs_nt = vecs[:, mask][:, :n_vecs]

    feat = np.hstack([vecs_nt.real, vecs_nt.imag])  

    norms = np.linalg.norm(feat, axis=1, keepdims=True)
    norms[norms == 0] = 1.0
    feat = feat / norms

    km = KMeans(n_clusters=n_clusters, n_init=20, random_state=SEED)
    labels = km.fit_predict(feat)
    return labels, feat, vals, vecs

def plot_clusters_pca(feat, labels, title="Clustering espectral (PCA de autovectores)", 
                      vals=None, vecs=None):
    """
    Visualiza el embedding espectral reducido a 2D con PCA.
    AdemÃ¡s imprime todas las dimensiones y explicaciones matemÃ¡ticas:
    - nÃºmero de nodos
    - nÃºmero de autovalores/autovectores
    - dimensiones del embedding espectral
    - dimensiones reducidas por PCA
    """

    print("\n================= INFORME DE ESTRUCTURA MATEMÃTICA =================\n")
    
    if vals is not None and vecs is not None:
        print(" MATRIZ ESPECTRAL (valores propios y vectores propios)")
        print(f"- Cantidad de autovalores calculados: {len(vals)}")
        print(f"- Cantidad de autovectores calculados: {vecs.shape[1]}")
        print(f"- DimensiÃ³n de cada autovector: {vecs.shape[0]}")

        total_theoretical = vecs.shape[0]
        computed = vecs.shape[1]
        percent_used = (computed / total_theoretical) * 100

        print(f"- Cantidad total posible de autovectores (tamaÃ±o de P): {total_theoretical}")
        print(f"- Autovectores no calculados: {total_theoretical - computed}")
        print(f"- Porcentaje de autovectores usados: {percent_used:.4f}%")
        print("  (Solo se calcularon los modos dominantes, que capturan la dinÃ¡mica global del sistema.)")
        print("  (El resto de autovectores representan modos de variaciÃ³n menores o ruido numÃ©rico.)")
        print(f"  (Cada autovector tiene un valor por nodo del sistema, total {vecs.shape[0]} nodos.)")
    else:
        print("No se pasaron 'vals' ni 'vecs'. Solo se mostrarÃ¡ informaciÃ³n del embedding PCA.")

    N, D = feat.shape
    print("\nEMBEDDING ESPECTRAL")
    print(f"- NÃºmero de nodos (filas): {N}")
    print(f"- Dimensiones originales (columnas): {D}")
    print(f"- Estructura de features: {D//2} autovectores â†’ partes real e imaginaria concatenadas")
    print("  (Cada nodo se representa en un espacio de 2Ã—n_vecs dimensiones)")
    print("  (Esto preserva informaciÃ³n de fase y magnitud de los modos complejos del sistema)")
    
    pca = PCA(n_components=2, random_state=SEED)
    xy = pca.fit_transform(feat)
    var_exp = pca.explained_variance_ratio_

    
    print("\nPCA (AnÃ¡lisis de Componentes Principales)")
    print(f"- Componentes usados: 2")
    print(f"- Varianza explicada por PC1: {var_exp[0]*100:.2f}%")
    print(f"- Varianza explicada por PC2: {var_exp[1]*100:.2f}%")
    print(f"- Varianza total capturada: {(var_exp[0]+var_exp[1])*100:.2f}%")
    print(f"- Varianza no capturada (resto de dimensiones): {(1 - var_exp[:2].sum())*100:.2f}%")
    print("\n  PC1 y PC2 son combinaciones lineales ortogonales de las dimensiones originales.")
    print("  Cada eje del grÃ¡fico corresponde a una direcciÃ³n de mÃ¡xima varianza en el embedding.")
    print("  En este plano, los puntos mÃ¡s separados reflejan nodos con dinÃ¡micas espectrales distintas.\n")

    print("=====================================================================\n")
    
    plt.figure(figsize=(6.8,5.4))
    for c in np.unique(labels):
        m = labels == c
        plt.scatter(xy[m,0], xy[m,1], s=8, label=f"cluster {c}")

    plt.title(f"{title}\nVarianza explicada: PC1 = {var_exp[0]*100:.2f}% | PC2 = {var_exp[1]*100:.2f}%")
    plt.xlabel(f"PC1 ({var_exp[0]*100:.2f}% varianza)")
    plt.ylabel(f"PC2 ({var_exp[1]*100:.2f}% varianza)")
    plt.legend(markerscale=2, fontsize=9)
    plt.grid(True, alpha=0.3)
    plt.show()



def load_grid_coords(grid_path, one_indexed=True):
    """
    Lee archivo .grid con mapping: idx lon lat ... (los dos Ãºltimos nÃºmeros pueden ignorarse).
    Devuelve arrays lon, lat con orden por Ã­ndice.
    """
    raw = []
    with open(grid_path, "r", encoding="utf-8") as f:
        for line in f:
            parts = line.strip().split()
            if not parts: 
                continue
            if len(parts) < 3:
                continue
            try:
                idx = int(parts[0])
                lon = float(parts[1])
                lat = float(parts[2])
                raw.append((idx, lon, lat))
            except:
                continue
    if not raw:
        raise ValueError("No se pudieron leer coordenadas desde el .grid")

    raw = np.array(raw, dtype=float)
    idx = raw[:,0].astype(int)
    if one_indexed:
        idx -= 1
    N = idx.max() + 1
    lon = np.zeros(N); lat = np.zeros(N)
    lon[idx] = raw[:,1]; lat[idx] = raw[:,2]
    return lon, lat

def plot_clusters_geo(lon, lat, labels, title="Clusters sobre mapa (lon/lat)"):
    """
    Dispersa nodos por lon/lat coloreados por cluster. (Mapa simple sin cartopy.)
    """
    plt.figure(figsize=(7,5.5))
    for c in np.unique(labels):
        m = labels == c
        plt.scatter(lon[m], lat[m], s=6, label=f"cluster {c}")
    plt.title(title)
    plt.xlabel("Longitud"); plt.ylabel("Latitud")
    plt.legend(markerscale=2, fontsize=9)
    plt.grid(True, alpha=0.3)
    plt.show()

meses = ["enero", "febrero", "marzo", "abril", "mayo", "junio",
         "julio", "agosto", "septiembre", "octubre", "noviembre", "diciembre"]

if __name__ == "__main__":
    mes_nombre = meses[0] 
    nombre_matriz = f"15_{mes_nombre}_2002.matrix"
    directorio_matrices = os.path.join("..", "Ser Giaconi Matrices", "2002_monthbymonth")
    path = os.path.join(directorio_matrices, nombre_matriz)

    P = load_transport_matrix(path, one_indexed=True)
    _ = plot_eigs_complex(P, k=250, title=f"Espectro de autovalores: {mes_nombre.capitalize()} 2002")

    labels, feat, vals, vecs = spectral_clustering_from_P(
        P, n_vecs=6, n_clusters=6, random_state=SEED
    )
    plot_clusters_pca(feat, labels, title=f"Clustering espectral (PCA de autovectores) â€“ {mes_nombre.capitalize()} 2002", vecs=vecs, vals=vals)
    
    
    
print("""
CÃ³mo leer los colores (clusters)
Cada color corresponde a un cluster detectado por KMeans en el espacio espectral.
Los nodos del mismo color tienen autovectores similares,
es decir, dinÃ¡micas de transporte parecidas (pueden pertenecer a una misma regiÃ³n o comunidad del flujo).
Las fronteras entre colores son zonas donde el comportamiento cambia abruptamente
(por ejemplo, bordes entre cuencas, o regiones con distinta conectividad hidrodinÃ¡mica).

CÃ³mo interpretar la forma del grÃ¡fico
El patrÃ³n en forma de arco o â€œsemicÃ­rculoâ€ es tÃ­pico de embeddings espectrales.
Los autovectores estÃ¡n correlacionados con modos oscilatorios o de mezcla.
La forma curva indica que existen modos graduales de transiciÃ³n,
no cortes abruptos entre comunidades.
Si los puntos formaran grupos compactos claramente separados, indicarÃ­a comunidades muy diferenciadas en la red de transporte.
Si se ven conectados (como un continuo), el sistema tiene zonas intermedias o mixtas.
""")


















































#%%


def calcular_entropia_estacionaria(P):
    """
    Calcula la entropÃ­a estacionaria del sistema a partir del autovector
    asociado al autovalor dominante Î»=1 (estado estacionario).
    TambiÃ©n entrega una interpretaciÃ³n automÃ¡tica del grado de mezcla.

    Por quÃ© se usa P.T:
    - P describe transiciones "de i a j" por filas (P_ij).
    - El estado estacionario Ï€ cumple: Ï€^T P = Ï€^T
      â†’ en forma matricial: P^T Ï€ = Ï€
      Por eso se calcula el autovector derecho de P.T (o el izquierdo de P).
    """
    # calcular el autovector estacionario asociado al autovalor mÃ¡s grande (â‰ˆ1)
    vals, vecs = eigs(P.T, k=1, which='LM')
    pi = np.abs(vecs[:, 0].real)
    pi /= pi.sum()  # normalizar para que sume 1

    # calcular entropÃ­a
    H = -np.sum(pi * np.log(pi + 1e-12))
    Hmax = np.log(len(pi))
    Hnorm = H / Hmax

    print(f"\n EntropÃ­a estacionaria: {H:.4f}")
    print(f" EntropÃ­a mÃ¡xima posible (ln N): {Hmax:.4f}")
    print(f" EntropÃ­a normalizada (H/Hmax): {Hnorm:.4f}\n")

    # interpretaciÃ³n automÃ¡tica segÃºn rango
    if Hnorm > 0.85:
        interpretacion = "Sistema altamente mezclado (cercano a mÃ¡xima entropÃ­a, flujo muy homogÃ©neo)."
    elif Hnorm > 0.65:
        interpretacion = "Sistema parcialmente mezclado, con estructura leve en los flujos."
    elif Hnorm > 0.4:
        interpretacion = "Sistema con estructuras persistentes (regiones de flujo mÃ¡s concentradas)."
    elif Hnorm > 0.2:
        interpretacion = "Sistema fuertemente estructurado, presencia de regiones atrapantes o poco conectadas."
    else:
        interpretacion = "Sistema muy ordenado o direccional: el flujo sigue trayectorias casi deterministas."

    print(" InterpretaciÃ³n automÃ¡tica:")
    print(f"   {interpretacion}\n")
    print(" Nota: P se transpone porque el estado estacionario Ï€ cumple Páµ—Â·Ï€ = Ï€,")
    print("   es decir, las probabilidades estacionarias son autovectores izquierdos de P.\n")

    return H, Hmax, Hnorm






H, Hmax, Hnorm = calcular_entropia_estacionaria(P)


#%%

print(r"""
RelaciÃ³n matemÃ¡tica entre P, Páµ€ y Pâ»Â¹

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€------------------------------------------------------------
â”‚ OperaciÃ³n          â”‚              ExpresiÃ³n matemÃ¡tica              â”‚                             Significado                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€---------â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€------------------------------------â”¤
â”‚ EvoluciÃ³n directa  â”‚  xâ‚œâ‚Šâ‚ = P Â· xâ‚œ                                  â”‚  Paso temporal normal (dinÃ¡mica hacia adelante).                 â”‚
â”‚ Proceso inverso    â”‚  Páµ€ Â· Ï€ = Ï€                                    â”‚  Equilibrio o dinÃ¡mica inversa (autovector estacionario).        â”‚
â”‚ Retroceso exacto   â”‚  xâ‚œ = Pâ»Â¹ Â· xâ‚œâ‚Šâ‚                                â”‚  Retroceso en el tiempo (sin interpretaciÃ³n probabilÃ­stica).     â”‚
â”‚ Reversibilidad     â”‚  D_Ï€ Â· P = Páµ€ Â· D_Ï€                            â”‚  Se cumple solo si el sistema es reversible (flujo equilibrado). â”‚
â”‚ Similitud espectralâ”‚ Páµ€ = D_Ï€ Â· P Â· D_Ï€â»Â¹                           â”‚  P y Páµ€ tienen los mismos autovalores si hay reversibilidad.     â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-

Donde:
 - P  âˆˆ â„â¿Ë£â¿  es la matriz de transiciÃ³n (estocÃ¡stica por filas).
 - Ï€  es el vector estacionario tal que  Páµ€Â·Ï€ = Ï€.
 - D_Ï€ = diag(Ï€)  es la matriz diagonal con Ï€ en la diagonal.
 - Si  D_Ï€Â·P = Páµ€Â·D_Ï€,  el sistema cumple equilibrio detallado (reversible).
""")











#%% 
def analizar_propiedades_matriz(P):
    """
    EvalÃºa propiedades algebraicas de la matriz de transporte P:
    - Si es cuadrada
    - Si es invertible
    - Si es simÃ©trica (P = Páµ€)
    - Si es hermitiana (P = Pá´´)
    - Si es dispersa (sparse)
    - Si es estocÃ¡stica (filas suman 1)
    """

    print("\n================= INFORME DE PROPIEDADES DE LA MATRIZ P =================\n")
    print(f"Dimensiones de P: {P.shape[0]} x {P.shape[1]}")

    try:
        P_dense = P.toarray()
    except Exception:
        P_dense = np.array(P)

    if P.shape[0] == P.shape[1]:
        print("P es cuadrada (puede tener inversa si el determinante â‰  0).")
    else:
        print("P no es cuadrada: no puede invertirse.")
        return

    is_symmetric = np.allclose(P_dense, P_dense.T, atol=1e-10)
    is_hermitian = np.allclose(P_dense, P_dense.conj().T, atol=1e-10)

    print(f"Es simÃ©trica: {is_symmetric}")
    print(f"Es hermitiana (P = Pá´´): {is_hermitian}")

    sparsity = 1.0 - (P.count_nonzero() / (P.shape[0] * P.shape[1]))
    print(f"DispersiÃ³n (proporciÃ³n de ceros): {sparsity*100:.2f}%")

    row_sums = np.array(P.sum(axis=1)).ravel()
    stochastic_ok = np.allclose(row_sums, np.ones_like(row_sums), atol=1e-10)
    print(f"EstocÃ¡stica por filas: {stochastic_ok}")

    print("\nIntentando calcular la inversa de P (puede fallar si es singular)...")
    try:
        from numpy.linalg import inv, LinAlgError
        P_inv = inv(P_dense)
        print("P es invertible (determinante â‰  0).")
        det_val = np.linalg.det(P_dense)
        print(f"Determinante de P: {det_val:.6e}")
    except Exception as e:
        print(f"P no es invertible: {e}")
        P_inv = None

    try:
        vals = np.linalg.eigvals(P_dense)
        print(f"\nAutovalor mÃ¡ximo en magnitud: {np.max(np.abs(vals)):.4f}")
        print(f"Autovalor mÃ­nimo en magnitud: {np.min(np.abs(vals)):.4e}")
    except Exception:
        print("No se pudieron calcular autovalores (matriz muy grande o dispersa).")

    print("\nğŸ“˜ InterpretaciÃ³n:")
    if is_hermitian:
        print("   â†’ P es hermitiana: sus autovalores son reales y su base es ortogonal.")
    elif is_symmetric:
        print("   â†’ P es simÃ©trica (caso real de hermitiana).")
    else:
        print("   â†’ P NO es hermitiana: puede tener autovalores complejos (sistema no reversible).")

    if stochastic_ok:
        print("   â†’ P conserva probabilidad (cada fila suma 1).")
    else:
        print("   â†’ P no es perfectamente estocÃ¡stica (puede haber errores de normalizaciÃ³n numÃ©rica).")

    if P_inv is None:
        print("   â†’ No se puede invertir: el flujo no tiene trayectoria inversa Ãºnica (sistema disipativo).")
    else:
        print("   â†’ Se obtuvo Pâ»Â¹ (interpretar solo algebraicamente, no como transiciÃ³n inversa).")

    print("\n=======================================================================\n")
    return P_inv

# Ejecutar el anÃ¡lisis
P_inv = analizar_propiedades_matriz(P)








print(r"""
INTERPRETACIÃ“N: MATRIZ DE TRANSPORTE NO INVERTIBLE (SINGULAR)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MatemÃ¡ticamente:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- det(P) = 0   â†’  la matriz no tiene inversa.
- Existen filas o columnas linealmente dependientes.
- El rango de P es menor que su dimensiÃ³n (rango(P) < N).
- El sistema PÂ·x = y no tiene soluciÃ³n Ãºnica (puede tener infinitas o ninguna).
- Existe un espacio nulo no trivial:  âˆƒ v â‰  0 tal que  PÂ·v = 0.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Dinamismo y teorÃ­a de Markov:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- El proceso no es reversible (no se puede reconstruir el estado previo).
- El sistema pierde informaciÃ³n temporalmente (no hay dinÃ¡mica uno a uno).
- La probabilidad puede concentrarse en subconjuntos del dominio.
- Existen estados absorbentes o regiones atrapantes.
- El equilibrio estacionario no es Ãºnico (mÃºltiples Ï€ posibles).
- Puede haber componentes comunicantes: subredes que no intercambian flujo.
- Algunos nodos nunca son visitados o dejan de recibir masa (columnas nulas).
- El flujo neto es disipativo (no conserva â€œinformaciÃ³nâ€ bajo evoluciÃ³n inversa).

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
InterpretaciÃ³n fÃ­sica (transporte oceÃ¡nico, difusivo o ambiental):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Existen zonas atrapantes donde el flujo entra pero no sale.
- Existen zonas emisoras (fuentes) que expulsan masa sin recibirla.
- Parte de la masa puede â€œsalir del dominioâ€ o disiparse fuera del sistema.
- El transporte no es perfectamente conservativo (puede haber fuga o pÃ©rdida).
- Dos regiones pueden tener dinÃ¡micas indistinguibles (redundancia espacial).
- La red presenta caminos sin retorno (asimetrÃ­a direccional del flujo).
- Puede existir conectividad parcial: el dominio se fragmenta en subcuencas.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Consecuencias espectrales:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Al menos un autovalor es exactamente 0 â†’ modo completamente disipativo.
- Autovalores con |Î»| < 1 â†’ relajaciones hacia estados absorbentes.
- El autovalor Î»=1 puede tener multiplicidad >1 â†’ mÃºltiples equilibrios posibles.
- El espectro no estÃ¡ en el cÃ­rculo unidad completo (no conservativo).

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Implicancias prÃ¡cticas:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- No se puede invertir P algebraicamente (no existe Pâ»Â¹).
- No existe un proceso temporal â€œhacia atrÃ¡sâ€ Ãºnico.
- Se requiere pseudo-inversa (Mooreâ€“Penrose) o anÃ¡lisis por subespacios.
- Los resultados de clustering o entropÃ­a deben interpretarse como dinÃ¡micas
  proyectadas o agregadas, no como flujos perfectamente reversibles.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Resumen intuitivo:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Una matriz de transporte no invertible representa un sistema:
â†’ con direccionalidad o disipaciÃ³n,
â†’ con pÃ©rdida de informaciÃ³n o mezcla irreversible,
â†’ donde solo existe dinÃ¡mica hacia adelante en el tiempo,
â†’ y donde el equilibrio puede no ser Ãºnico o alcanzarse por varios caminos.
""")















#%%
def analizar_propiedades_transpuesta(P):
    """
    Analiza las propiedades algebraicas y estructurales de la traspuesta Páµ€:
    - SimetrÃ­a, hermiticidad, estocasticidad
    - DispersiÃ³n (sparsity)
    - ComparaciÃ³n con P (reversibilidad)
    - InterpretaciÃ³n fÃ­sica y dinÃ¡mica

    Retorna la traspuesta Páµ€ (formato disperso si aplica).
    """

    print("\n================= ANÃLISIS DE LA MATRIZ TRASPUESTA (Páµ€) =================")

    P_T = P.transpose().tocsr()
    N = P.shape[0]
    print(f"Dimensiones de P:  {P.shape[0]} Ã— {P.shape[1]}")
    print(f"Dimensiones de Páµ€: {P_T.shape[0]} Ã— {P_T.shape[1]}")

    try:
        P_dense = P.toarray()
        P_T_dense = P_T.toarray()
    except Exception:
        print("Matriz muy grande; se analizarÃ¡ solo estructura dispersa.")
        P_dense = None
        P_T_dense = None

    if P_dense is not None:
        is_symmetric = np.allclose(P_dense, P_T_dense, atol=1e-10)
        is_hermitian = np.allclose(P_dense, P_dense.conj().T, atol=1e-10)
    else:
        is_symmetric = np.nan
        is_hermitian = np.nan

    print(f"P es simÃ©trica (P = Páµ€): {is_symmetric}")
    print(f"P es hermitiana (P = Pá´´): {is_hermitian}")

    nnz = P_T.count_nonzero()
    sparsity = 1.0 - nnz / (P_T.shape[0] * P_T.shape[1])
    print(f"DispersiÃ³n (proporciÃ³n de ceros): {sparsity*100:.2f}%")

    row_sums_T = np.array(P_T.sum(axis=1)).ravel()
    stochastic_T = np.allclose(row_sums_T, np.ones_like(row_sums_T), atol=1e-10)
    print(f"EstocÃ¡stica por filas (Páµ€): {stochastic_T}")

    if P_dense is not None and N < 800:
        eig_P = np.linalg.eigvals(P_dense)
        eig_PT = np.linalg.eigvals(P_T_dense)
        same_spectrum = np.allclose(np.sort_complex(eig_P), np.sort_complex(eig_PT), atol=1e-8)
        print(f"P y Páµ€ tienen los mismos autovalores: {same_spectrum}")
    else:
        same_spectrum = None
        print("No se comparÃ³ el espectro (matriz muy grande).")

    try:
        vals, vecs = eigs(P.T, k=1, which='LM')
        pi = np.abs(vecs[:,0].real)
        pi /= pi.sum()
        D_pi = np.diag(pi)
        left = D_pi @ P.toarray()
        right = P_T.toarray() @ D_pi
        reversible = np.allclose(left, right, atol=1e-6)
    except Exception:
        reversible = None
    print(f"Cumple equilibrio detallado (reversible): {reversible}")

    print("\nINTERPRETACIÃ“N:")
    if is_hermitian:
        print("â†’ P es hermitiana: dinÃ¡mica completamente reversible, autovalores reales.")
    elif is_symmetric:
        print("â†’ P es simÃ©trica: flujo bidireccional con igual probabilidad iâ†”j.")
    else:
        print("â†’ P NO es simÃ©trica ni hermitiana: el sistema tiene direccionalidad o disipaciÃ³n.")

    if stochastic_T:
        print("â†’ Páµ€ conserva probabilidad (estocÃ¡stica por filas).")
    else:
        print("â†’ Páµ€ no conserva masa exactamente (posible pÃ©rdida o acumulaciÃ³n).")

    if reversible:
        print("â†’ El sistema cumple equilibrio detallado: flujo hacia adelante y hacia atrÃ¡s balanceado.")
    else:
        print("â†’ El sistema NO es reversible: existen trayectorias preferenciales o regiones atrapantes.")

    print("==========================================================================\n")

    return P_T

P_T = analizar_propiedades_transpuesta(P)
